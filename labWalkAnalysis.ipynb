{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm, metrics\n",
    "import datetime as dt\n",
    "\n",
    "import wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = []\n",
    "label = [];\n",
    "\n",
    "for i in range(45):\n",
    "\n",
    "    index = '{:03}'.format(i)\n",
    "    fileName = 'LabWalks/co' + index + '_base'\n",
    "    if os.path.isfile(fileName + '.hea'):\n",
    "        record = wfdb.rdrecord(fileName)\n",
    "        data = record.p_signal\n",
    "        tmp = np.linalg.norm(data[:,0:3],axis=1)\n",
    "        #print(np.size(tmp))\n",
    "        allData.append(tmp)\n",
    "        label.append(0)\n",
    "    \n",
    "    index = '{:03}'.format(i)\n",
    "    fileName = 'LabWalks/fl' + index + '_base'\n",
    "    if os.path.isfile(fileName + '.hea'):\n",
    "        record = wfdb.rdrecord(fileName)\n",
    "        data = record.p_signal\n",
    "        tmp = np.linalg.norm(data[:,0:3],axis=1)\n",
    "        #print(np.size(tmp))\n",
    "        allData.append(tmp)\n",
    "        label.append(1)\n",
    "\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    allData, label, test_size=0.2,random_state=42)\n",
    "\n",
    "plt.plot(allData[2])\n",
    "plt.figure()\n",
    "a = gaussian_filter(allData[3], sigma = 10)\n",
    "plt.plot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SkipedCycles = 3\n",
    "NumOfCycles = 40\n",
    "NumOfSamples = 1000\n",
    "\n",
    "X_t = []\n",
    "y_t = []\n",
    "\n",
    "alldata = X_train\n",
    "numItems = -1\n",
    "for one in alldata:\n",
    "    numItems = numItems + 1;\n",
    "    pdata = one - 1\n",
    "    scaler = np.sort(pdata)[int(len(pdata)*0.98)]\n",
    "    scaledData = pdata / scaler\n",
    "    filterdData = gaussian_filter(scaledData, sigma = 20)\n",
    "\n",
    "    index = 0\n",
    "    #plt.figure()\n",
    "    for i in range(SkipedCycles):\n",
    "        while index + 1 < len(one):\n",
    "            index = index + 1\n",
    "            if filterdData[index] > max(filterdData[index-1], filterdData[index+1]):\n",
    "                break;\n",
    "    index = index + 1;\n",
    "    while index + 1 < len(one):\n",
    "        startIndex = index\n",
    "        #print(startIndex)\n",
    "        while index + 1 < len(one) and filterdData[index] < max(filterdData[index-1], filterdData[index+1]):\n",
    "            index = index + 1\n",
    "        index = index + 1\n",
    "        endIndex = index  \n",
    "        \n",
    "        while index + 1 < len(one) and filterdData[index] < max(filterdData[index-1], filterdData[index+1]):\n",
    "            index = index + 1\n",
    "        index = index + 1\n",
    "        endIndex = index \n",
    "        #print(endIndex)\n",
    "\n",
    "        if endIndex < len(one) - 1:\n",
    "            usedData = scaledData[startIndex: endIndex]\n",
    "            f = interp1d(range(len(usedData)), usedData, kind='cubic')\n",
    "            x = np.linspace(0, len(usedData)-1, num=NumOfSamples, endpoint=False)\n",
    "            processedData = f(x)\n",
    "            #plt.plot(processedData)\n",
    "            X_t.append(processedData)\n",
    "            y_t.append(y_train[numItems]) \n",
    "\n",
    "print(np.shape(X_t), np.shape(y_t))\n",
    "plt.plot(np.array(X_t).T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(X_t).T[:,0:5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SkipedCycles = 3\n",
    "NumOfCycles = 40\n",
    "NumOfSamples = 1000\n",
    "\n",
    "X_ts = []\n",
    "y_ts = []\n",
    "\n",
    "alldata = X_test\n",
    "numItems = -1\n",
    "for one in alldata:\n",
    "    numItems = numItems + 1;\n",
    "    pdata = one - 1\n",
    "    scaler = np.sort(pdata)[int(len(pdata)*0.98)]\n",
    "    scaledData = pdata / scaler\n",
    "    filterdData = gaussian_filter(scaledData, sigma = 20)\n",
    "\n",
    "    index = 0\n",
    "    #plt.figure()\n",
    "    for i in range(SkipedCycles):\n",
    "        while index + 1 < len(one):\n",
    "            index = index + 1\n",
    "            if filterdData[index] > max(filterdData[index-1], filterdData[index+1]):\n",
    "                break;\n",
    "    index = index + 1;\n",
    "    while index + 1 < len(one):\n",
    "        startIndex = index\n",
    "        #print(startIndex)\n",
    "        while index + 1 < len(one) and filterdData[index] < max(filterdData[index-1], filterdData[index+1]):\n",
    "            index = index + 1\n",
    "        index = index + 1\n",
    "        endIndex = index  \n",
    "        \n",
    "        while index + 1 < len(one) and filterdData[index] < max(filterdData[index-1], filterdData[index+1]):\n",
    "            index = index + 1\n",
    "        index = index + 1\n",
    "        endIndex = index  \n",
    "        #print(endIndex)\n",
    "\n",
    "        if endIndex < len(one) - 1:\n",
    "            usedData = scaledData[startIndex: endIndex]\n",
    "            f = interp1d(range(len(usedData)), usedData, kind='cubic')\n",
    "            x = np.linspace(0, len(usedData)-1, num=NumOfSamples, endpoint=False)\n",
    "            processedData = f(x)\n",
    "            #plt.plot(processedData)\n",
    "            X_ts.append(processedData)\n",
    "            y_ts.append(y_test[numItems]) \n",
    "\n",
    "print(np.shape(X_ts), np.shape(y_ts))\n",
    "plt.plot(np.array(X_ts).T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(X_ts[0:2]).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = check_random_state(0)\n",
    "permutation = random_state.permutation(np.array(X_t).shape[0])\n",
    "X_tf = np.array(X_t)[permutation]\n",
    "y_tf = np.array(y_t)[permutation]\n",
    "\n",
    "permutation = random_state.permutation(np.array(X_ts).shape[0])\n",
    "X_tsf = np.array(X_ts)[permutation]\n",
    "y_tsf = np.array(y_ts)[permutation]\n",
    "\n",
    "print(np.shape(X_tf), np.shape(y_tf))\n",
    "print(np.shape(X_tsf), np.shape(y_tsf))\n",
    "plt.plot(y_tsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2).fit(X_tf)\n",
    "pca_2d = pca.transform(X_tf)\n",
    "\n",
    "\n",
    "import pylab as pl\n",
    "for i in range(0, pca_2d.shape[0]):\n",
    "    if y_tf[i] == 0:\n",
    "        c1 = pl.scatter(pca_2d[i,0],pca_2d[i,1],c='r',    marker='+')\n",
    "    elif y_tf[i] == 1:\n",
    "        c2 = pl.scatter(pca_2d[i,0],pca_2d[i,1],c='g',    marker='o')\n",
    "\n",
    "        \n",
    "pl.legend([c1, c2], ['Nonfaller', 'Faller'])\n",
    "pl.title('Training dataset with 2 classes')\n",
    "pl.show()\n",
    "\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to Scale and visualize the embedding vectors\n",
    "\n",
    "def plot_embedding(X, y, title=None):\n",
    "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min)     \n",
    "    plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    for i in range(X.shape[0]):\n",
    "        plt.text(X[i, 0], X[i, 1], str(y[i]),\n",
    "                 color=plt.cm.Set1(y[i] / 10.),\n",
    "                 fontdict={'weight': 'bold', 'size': 9})\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "        \n",
    "from sklearn import manifold\n",
    "#降维\n",
    "tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "\n",
    "X_tsne = tsne.fit_transform(X_tf)\n",
    "#绘图\n",
    "plot_embedding(X_tsne,y_tf*5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Fabian Pedregosa <fabian.pedregosa@inria.fr>\n",
    "#          Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#          Mathieu Blondel <mathieu@mblondel.org>\n",
    "#          Gael Varoquaux\n",
    "# License: BSD 3 clause (C) INRIA 2011\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import offsetbox\n",
    "from sklearn import (manifold, datasets, decomposition, ensemble,\n",
    "                     discriminant_analysis, random_projection, neighbors)\n",
    "X = X_tf\n",
    "y = y_tf*5\n",
    "# ----------------------------------------------------------------------\n",
    "# Scale and visualize the embedding vectors\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Random 2D projection using a random unitary matrix\n",
    "print(\"Computing random projection\")\n",
    "rp = random_projection.SparseRandomProjection(n_components=2, random_state=42)\n",
    "X_projected = rp.fit_transform(X)\n",
    "plot_embedding(X_projected, y, \"Random Projection of the digits\")\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Projection on to the first 2 principal components\n",
    "\n",
    "print(\"Computing PCA projection\")\n",
    "\n",
    "X_pca = decomposition.TruncatedSVD(n_components=2).fit_transform(X)\n",
    "plot_embedding(X_pca, y,\n",
    "               \"Principal Components projection of the digits\" )\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Projection on to the first 2 linear discriminant components\n",
    "'''\n",
    "print(\"Computing Linear Discriminant Analysis projection\")\n",
    "X2 = X.copy()\n",
    "X2.flat[::X.shape[1] + 1] += 0.01  # Make X invertible\n",
    "\n",
    "X_lda = discriminant_analysis.LinearDiscriminantAnalysis(n_components=2).fit_transform(X2, y)\n",
    "plot_embedding(X_lda, y,\n",
    "               \"Linear Discriminant projection of the digits\")\n",
    "'''\n",
    "n_neighbors = 30\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Isomap projection of the digits dataset\n",
    "print(\"Computing Isomap projection\")\n",
    "\n",
    "X_iso = manifold.Isomap(n_neighbors, n_components=2).fit_transform(X)\n",
    "print(\"Done.\")\n",
    "plot_embedding(X_iso, y,\n",
    "               \"Isomap projection of the digits\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Locally linear embedding of the digits dataset\n",
    "print(\"Computing LLE embedding\")\n",
    "clf = manifold.LocallyLinearEmbedding(n_neighbors, n_components=2,\n",
    "                                      method='standard')\n",
    "\n",
    "X_lle = clf.fit_transform(X)\n",
    "print(\"Done. Reconstruction error: %g\" % clf.reconstruction_error_)\n",
    "plot_embedding(X_lle, y,\n",
    "               \"Locally Linear Embedding of the digits\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Modified Locally linear embedding of the digits dataset\n",
    "'''\n",
    "\n",
    "print(\"Computing modified LLE embedding\")\n",
    "clf = manifold.LocallyLinearEmbedding(n_neighbors, n_components=2,\n",
    "                                      method='modified')\n",
    "\n",
    "X_mlle = clf.fit_transform(X)\n",
    "print(\"Done. Reconstruction error: %g\" % clf.reconstruction_error_)\n",
    "plot_embedding(X_mlle, y,\n",
    "               \"Modified Locally Linear Embedding of the digits\")\n",
    "'''\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# HLLE embedding of the digits dataset\n",
    "'''\n",
    "\n",
    "print(\"Computing Hessian LLE embedding\")\n",
    "clf = manifold.LocallyLinearEmbedding(n_neighbors, n_components=2,\n",
    "                                      method='hessian')\n",
    "\n",
    "X_hlle = clf.fit_transform(X)\n",
    "print(\"Done. Reconstruction error: %g\" % clf.reconstruction_error_)\n",
    "plot_embedding(X_hlle, y,\n",
    "               \"Hessian Locally Linear Embedding of the digits\")\n",
    "'''\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# LTSA embedding of the digits dataset\n",
    "'''\n",
    "print(\"Computing LTSA embedding\")\n",
    "clf = manifold.LocallyLinearEmbedding(n_neighbors, n_components=2,\n",
    "                                      method='ltsa')\n",
    "\n",
    "X_ltsa = clf.fit_transform(X)\n",
    "print(\"Done. Reconstruction error: %g\" % clf.reconstruction_error_)\n",
    "plot_embedding(X_ltsa, y,\n",
    "               \"Local Tangent Space Alignment of the digits\")\n",
    "'''\n",
    "# ----------------------------------------------------------------------\n",
    "# MDS  embedding of the digits dataset\n",
    "print(\"Computing MDS embedding\")\n",
    "clf = manifold.MDS(n_components=2, n_init=1, max_iter=100)\n",
    "\n",
    "X_mds = clf.fit_transform(X)\n",
    "print(\"Done. Stress: %f\" % clf.stress_)\n",
    "plot_embedding(X_mds, y,\n",
    "               \"MDS embedding of the digits\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Random Trees embedding of the digits dataset\n",
    "print(\"Computing Totally Random Trees embedding\")\n",
    "hasher = ensemble.RandomTreesEmbedding(n_estimators=200, random_state=0,\n",
    "                                       max_depth=5)\n",
    "X_transformed = hasher.fit_transform(X)\n",
    "pca = decomposition.TruncatedSVD(n_components=2)\n",
    "X_reduced = pca.fit_transform(X_transformed)\n",
    "\n",
    "plot_embedding(X_reduced, y,\n",
    "               \"Random forest embedding of the digits\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Spectral embedding of the digits dataset\n",
    "print(\"Computing Spectral embedding\")\n",
    "embedder = manifold.SpectralEmbedding(n_components=2, random_state=0,\n",
    "                                      eigen_solver=\"arpack\")\n",
    "X_se = embedder.fit_transform(X)\n",
    "\n",
    "plot_embedding(X_se, y,\n",
    "               \"Spectral embedding of the digits\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# t-SNE embedding of the digits dataset\n",
    "print(\"Computing t-SNE embedding\")\n",
    "tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "plot_embedding(X_tsne, y,\n",
    "               \"t-SNE embedding of the digits\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# NCA projection of the digits dataset\n",
    "print(\"Computing NCA projection\")\n",
    "nca = neighbors.NeighborhoodComponentsAnalysis(n_components=2, random_state=0)\n",
    "\n",
    "X_nca = nca.fit_transform(X, y)\n",
    "\n",
    "plot_embedding(X_nca, y,\n",
    "               \"NCA embedding of the digits\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=500).fit(X_tf)\n",
    "X_tf_pca = pca.transform(X_tf)\n",
    "X_tsf_pca = pca.transform(X_tsf)\n",
    "\n",
    "\n",
    "param_C = 5\n",
    "param_gamma = 0.05\n",
    "\n",
    "classifier = svm.SVC(C=param_C,gamma=param_gamma,tol=0.001)\n",
    "#classifier = svm.LinearSVC(C=param_C)\n",
    "\n",
    "#We learn the digits on train part\n",
    "start_time = dt.datetime.now()\n",
    "print('Start learning at {}'.format(str(start_time)))\n",
    "classifier.fit(X_tf_pca, y_tf)\n",
    "end_time = dt.datetime.now() \n",
    "print('Stop learning {}'.format(str(end_time)))\n",
    "elapsed_time= end_time - start_time\n",
    "print('Elapsed learning {}'.format(str(elapsed_time)))\n",
    "\n",
    "expected = y_tsf\n",
    "predicted = classifier.predict(X_tsf_pca)\n",
    "print(expected)\n",
    "print(predicted)\n",
    "\n",
    "      \n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(\"Confusion matrix:\\n%s\" % cm)\n",
    "\n",
    "print(\"Accuracy={}\".format(metrics.accuracy_score(expected, predicted)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(X_tf, y_tf)\n",
    "\n",
    "expected = y_tsf\n",
    "predicted = rnd_clf.predict(X_tsf)\n",
    "print(expected)\n",
    "print(predicted)\n",
    "\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(\"Confusion matrix:\\n%s\" % cm)\n",
    "\n",
    "print(\"Accuracy={}\".format(metrics.accuracy_score(expected, predicted)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
