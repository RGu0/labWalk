{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "import wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = []\n",
    "label = [];\n",
    "\n",
    "for i in range(45):\n",
    "\n",
    "    index = '{:03}'.format(i)\n",
    "    fileName = 'LabWalks/co' + index + '_base'\n",
    "    if os.path.isfile(fileName + '.hea'):\n",
    "        record = wfdb.rdrecord(fileName)\n",
    "        data = record.p_signal\n",
    "        tmp = np.linalg.norm(data[:,0:3],axis=1)\n",
    "        #print(np.size(tmp))\n",
    "        allData.append(tmp)\n",
    "        label.append(0)\n",
    "    \n",
    "    index = '{:03}'.format(i)\n",
    "    fileName = 'LabWalks/fl' + index + '_base'\n",
    "    if os.path.isfile(fileName + '.hea'):\n",
    "        record = wfdb.rdrecord(fileName)\n",
    "        data = record.p_signal\n",
    "        tmp = np.linalg.norm(data[:,0:3],axis=1)\n",
    "        #print(np.size(tmp))\n",
    "        allData.append(tmp)\n",
    "        label.append(1)\n",
    "\n",
    "print(len(allData))\n",
    "print(len(label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(allData[3])\n",
    "plt.figure()\n",
    "a = gaussian_filter(allData[3], sigma = 10)\n",
    "plt.plot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm, metrics\n",
    "import datetime as dt\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    allData, label, test_size=0.2,random_state=42)\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SkipedCycles = 3\n",
    "NumOfCycles = 40\n",
    "NumOfSamples = 1000\n",
    "\n",
    "X_t = []\n",
    "y_t = []\n",
    "\n",
    "alldata = X_train\n",
    "numItems = -1\n",
    "for one in alldata:\n",
    "    numItems = numItems + 1;\n",
    "    pdata = one - 1\n",
    "    scaler = np.sort(pdata)[int(len(pdata)*0.98)]\n",
    "    scaledData = pdata / scaler\n",
    "    filterdData = gaussian_filter(scaledData, sigma = 20)\n",
    "\n",
    "    index = 0\n",
    "    #plt.figure()\n",
    "    for i in range(SkipedCycles):\n",
    "        while index + 1 < len(one):\n",
    "            index = index + 1\n",
    "            if filterdData[index] > max(filterdData[index-1], filterdData[index+1]):\n",
    "                break;\n",
    "    index = index + 1;\n",
    "    while index + 1 < len(one):\n",
    "        startIndex = index\n",
    "        #print(startIndex)\n",
    "        while index + 1 < len(one) and filterdData[index] < max(filterdData[index-1], filterdData[index+1]):\n",
    "            index = index + 1\n",
    "        index = index + 1\n",
    "        endIndex = index  \n",
    "        #print(endIndex)\n",
    "\n",
    "        if endIndex < len(one) - 1:\n",
    "            usedData = scaledData[startIndex: endIndex]\n",
    "            f = interp1d(range(len(usedData)), usedData, kind='cubic')\n",
    "            x = np.linspace(0, len(usedData)-1, num=NumOfSamples, endpoint=False)\n",
    "            processedData = f(x)\n",
    "            #plt.plot(processedData)\n",
    "            X_t.append(processedData)\n",
    "            y_t.append(y_train[numItems]) \n",
    "\n",
    "print(np.shape(X_t), np.shape(y_t))\n",
    "plt.plot(y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SkipedCycles = 3\n",
    "NumOfCycles = 40\n",
    "NumOfSamples = 1000\n",
    "\n",
    "X_ts = []\n",
    "y_ts = []\n",
    "\n",
    "alldata = X_test\n",
    "numItems = -1\n",
    "for one in alldata:\n",
    "    numItems = numItems + 1;\n",
    "    pdata = one - 1\n",
    "    scaler = np.sort(pdata)[int(len(pdata)*0.98)]\n",
    "    scaledData = pdata / scaler\n",
    "    filterdData = gaussian_filter(scaledData, sigma = 20)\n",
    "\n",
    "    index = 0\n",
    "    #plt.figure()\n",
    "    for i in range(SkipedCycles):\n",
    "        while index + 1 < len(one):\n",
    "            index = index + 1\n",
    "            if filterdData[index] > max(filterdData[index-1], filterdData[index+1]):\n",
    "                break;\n",
    "    index = index + 1;\n",
    "    while index + 1 < len(one):\n",
    "        startIndex = index\n",
    "        #print(startIndex)\n",
    "        while index + 1 < len(one) and filterdData[index] < max(filterdData[index-1], filterdData[index+1]):\n",
    "            index = index + 1\n",
    "        index = index + 1\n",
    "        endIndex = index  \n",
    "        #print(endIndex)\n",
    "\n",
    "        if endIndex < len(one) - 1:\n",
    "            usedData = scaledData[startIndex: endIndex]\n",
    "            f = interp1d(range(len(usedData)), usedData, kind='cubic')\n",
    "            x = np.linspace(0, len(usedData)-1, num=NumOfSamples, endpoint=False)\n",
    "            processedData = f(x)\n",
    "            #plt.plot(processedData)\n",
    "            X_ts.append(processedData)\n",
    "            y_ts.append(y_test[numItems]) \n",
    "\n",
    "print(np.shape(X_ts), np.shape(y_ts))\n",
    "plt.plot(y_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = check_random_state(0)\n",
    "permutation = random_state.permutation(np.array(X_t).shape[0])\n",
    "X_tf = np.array(X_t)[permutation]\n",
    "y_tf = np.array(y_t)[permutation]\n",
    "\n",
    "permutation = random_state.permutation(np.array(X_ts).shape[0])\n",
    "X_tsf = np.array(X_ts)[permutation]\n",
    "y_tsf = np.array(y_ts)[permutation]\n",
    "\n",
    "print(np.shape(X_tf), np.shape(y_tf))\n",
    "print(np.shape(X_tsf), np.shape(y_tsf))\n",
    "plt.plot(y_tsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2).fit(X_tf)\n",
    "pca_2d = pca.transform(X_tf)\n",
    "\n",
    "\n",
    "import pylab as pl\n",
    "for i in range(0, pca_2d.shape[0]):\n",
    "    if y_tf[i] == 0:\n",
    "        c1 = pl.scatter(pca_2d[i,0],pca_2d[i,1],c='r',    marker='+')\n",
    "    elif y_tf[i] == 1:\n",
    "        c2 = pl.scatter(pca_2d[i,0],pca_2d[i,1],c='g',    marker='o')\n",
    "\n",
    "        \n",
    "pl.legend([c1, c2], ['Nonfaller', 'Faller'])\n",
    "pl.title('Training dataset with 2 classes')\n",
    "pl.show()\n",
    "\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_C = 1\n",
    "param_gamma = 0.1\n",
    "\n",
    "classifier = svm.SVC(C=param_C,gamma=param_gamma,tol=0.001)\n",
    "#classifier = svm.LinearSVC(C=param_C)\n",
    "\n",
    "#We learn the digits on train part\n",
    "start_time = dt.datetime.now()\n",
    "print('Start learning at {}'.format(str(start_time)))\n",
    "classifier.fit(X_tf, y_tf)\n",
    "end_time = dt.datetime.now() \n",
    "print('Stop learning {}'.format(str(end_time)))\n",
    "elapsed_time= end_time - start_time\n",
    "print('Elapsed learning {}'.format(str(elapsed_time)))\n",
    "\n",
    "expected = y_tsf\n",
    "predicted = classifier.predict(X_tsf)\n",
    "print(expected)\n",
    "print(predicted)\n",
    "\n",
    "      \n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(\"Confusion matrix:\\n%s\" % cm)\n",
    "\n",
    "print(\"Accuracy={}\".format(metrics.accuracy_score(expected, predicted)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree.export import export_text\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=0, max_depth=1)\n",
    "decision_tree = decision_tree.fit(X_tf, y_tf)\n",
    "r = export_text(decision_tree)\n",
    "\n",
    "expected = y_tsf\n",
    "predicted = decision_tree.predict(X_tsf)\n",
    "print(expected)\n",
    "print(predicted)\n",
    "\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(\"Confusion matrix:\\n%s\" % cm)\n",
    "\n",
    "print(\"Accuracy={}\".format(metrics.accuracy_score(expected, predicted)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(X_tf, y_tf)\n",
    "\n",
    "expected = y_tsf\n",
    "predicted = rnd_clf.predict(X_tsf)\n",
    "print(expected)\n",
    "print(predicted)\n",
    "\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(\"Confusion matrix:\\n%s\" % cm)\n",
    "\n",
    "print(\"Accuracy={}\".format(metrics.accuracy_score(expected, predicted)))\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
