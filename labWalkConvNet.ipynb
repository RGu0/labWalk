{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm, metrics\n",
    "import datetime as dt\n",
    "\n",
    "import wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = []\n",
    "label = [];\n",
    "\n",
    "for i in range(45):\n",
    "\n",
    "    index = '{:03}'.format(i)\n",
    "    fileName = 'LabWalks/co' + index + '_base'\n",
    "    if os.path.isfile(fileName + '.hea'):\n",
    "        record = wfdb.rdrecord(fileName)\n",
    "        data = record.p_signal\n",
    "        tmp = np.linalg.norm(data[:,0:3],axis=1)\n",
    "        #print(np.size(tmp))\n",
    "        allData.append(tmp)\n",
    "        label.append(0)\n",
    "    \n",
    "    index = '{:03}'.format(i)\n",
    "    fileName = 'LabWalks/fl' + index + '_base'\n",
    "    if os.path.isfile(fileName + '.hea'):\n",
    "        record = wfdb.rdrecord(fileName)\n",
    "        data = record.p_signal\n",
    "        tmp = np.linalg.norm(data[:,0:3],axis=1)\n",
    "        #print(np.size(tmp))\n",
    "        allData.append(tmp)\n",
    "        label.append(1)\n",
    "\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    allData, label, test_size=0.2,random_state=0)\n",
    "\n",
    "plt.plot(allData[3])\n",
    "plt.figure()\n",
    "a = gaussian_filter(allData[3], sigma = 10)\n",
    "plt.plot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SkipedCycles = 3\n",
    "NumOfCycles = 40\n",
    "NumOfSamples = 1000\n",
    "\n",
    "X_t = []\n",
    "y_t = []\n",
    "\n",
    "alldata = X_train\n",
    "numItems = -1\n",
    "for one in alldata:\n",
    "    numItems = numItems + 1;\n",
    "    pdata = one - 1\n",
    "    scaler = np.sort(pdata)[int(len(pdata)*0.98)]\n",
    "    scaledData = pdata / scaler\n",
    "    filterdData = gaussian_filter(scaledData, sigma = 20)\n",
    "\n",
    "    index = 0\n",
    "    #plt.figure()\n",
    "    for i in range(SkipedCycles):\n",
    "        while index + 1 < len(one):\n",
    "            index = index + 1\n",
    "            if filterdData[index] > max(filterdData[index-1], filterdData[index+1]):\n",
    "                break;\n",
    "    index = index + 1;\n",
    "    while index + 1 < len(one):\n",
    "        startIndex = index\n",
    "        #print(startIndex)\n",
    "        while index + 1 < len(one) and filterdData[index] < max(filterdData[index-1], filterdData[index+1]):\n",
    "            index = index + 1\n",
    "        index = index + 1\n",
    "        endIndex = index  \n",
    "        while index + 1 < len(one) and filterdData[index] < max(filterdData[index-1], filterdData[index+1]):\n",
    "            index = index + 1\n",
    "        index = index + 1\n",
    "        endIndex = index  \n",
    "        #print(endIndex)\n",
    "\n",
    "        if endIndex < len(one) - 1:\n",
    "            usedData = scaledData[startIndex: endIndex]\n",
    "            f = interp1d(range(len(usedData)), usedData, kind='cubic')\n",
    "            x = np.linspace(0, len(usedData)-1, num=NumOfSamples, endpoint=False)\n",
    "            processedData = f(x)\n",
    "            #plt.plot(processedData)\n",
    "            X_t.append(processedData)\n",
    "            y_t.append(y_train[numItems]) \n",
    "\n",
    "print(np.shape(X_t), np.shape(y_t))\n",
    "plt.plot(np.array(X_t).T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SkipedCycles = 3\n",
    "NumOfCycles = 40\n",
    "NumOfSamples = 1000\n",
    "\n",
    "X_ts = []\n",
    "y_ts = []\n",
    "\n",
    "alldata = X_test\n",
    "numItems = -1\n",
    "for one in alldata:\n",
    "    numItems = numItems + 1;\n",
    "    pdata = one - 1\n",
    "    scaler = np.sort(pdata)[int(len(pdata)*0.98)]\n",
    "    scaledData = pdata / scaler\n",
    "    filterdData = gaussian_filter(scaledData, sigma = 20)\n",
    "\n",
    "    index = 0\n",
    "    #plt.figure()\n",
    "    for i in range(SkipedCycles):\n",
    "        while index + 1 < len(one):\n",
    "            index = index + 1\n",
    "            if filterdData[index] > max(filterdData[index-1], filterdData[index+1]):\n",
    "                break;\n",
    "    index = index + 1;\n",
    "    while index + 1 < len(one):\n",
    "        startIndex = index\n",
    "        #print(startIndex)\n",
    "        while index + 1 < len(one) and filterdData[index] < max(filterdData[index-1], filterdData[index+1]):\n",
    "            index = index + 1\n",
    "        index = index + 1\n",
    "        endIndex = index  \n",
    "        \n",
    "        while index + 1 < len(one) and filterdData[index] < max(filterdData[index-1], filterdData[index+1]):\n",
    "            index = index + 1\n",
    "        index = index + 1\n",
    "        endIndex = index  \n",
    "        #print(endIndex)\n",
    "\n",
    "        if endIndex < len(one) - 1:\n",
    "            usedData = scaledData[startIndex: endIndex]\n",
    "            f = interp1d(range(len(usedData)), usedData, kind='cubic')\n",
    "            x = np.linspace(0, len(usedData)-1, num=NumOfSamples, endpoint=False)\n",
    "            processedData = f(x)\n",
    "            #plt.plot(processedData)\n",
    "            X_ts.append(processedData)\n",
    "            y_ts.append(y_test[numItems]) \n",
    "\n",
    "print(np.shape(X_ts), np.shape(y_ts))\n",
    "plt.plot(np.array(X_ts).T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tf =  np.array(X_t)\n",
    "X_tsf =  np.array(X_ts)\n",
    "\n",
    "X_tfn = np.concatenate((X_tf, np.flip(X_tf, 1)), axis=0)\n",
    "y_tfn = np.concatenate((y_tf, y_tf), axis=0)\n",
    "X_tsfn = np.concatenate((X_tsf, np.flip(X_tsf, 1)), axis=0)\n",
    "y_tsfn = np.concatenate((y_tsf, y_tsf), axis=0)\n",
    "\n",
    "print(np.shape(X_tfn))\n",
    "print(np.shape(y_tfn))\n",
    "print(np.shape(X_tsfn))\n",
    "print(np.shape(y_tsfn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = check_random_state(0)\n",
    "permutation = random_state.permutation(np.array(X_tfn).shape[0])\n",
    "X_tf = np.array(X_tfn)[permutation]\n",
    "y_tf = np.array(y_tfn)[permutation]\n",
    "\n",
    "permutation = random_state.permutation(np.array(X_tsfn).shape[0])\n",
    "X_tsf = np.array(X_tsfn)[permutation]\n",
    "y_tsf = np.array(y_tsfn)[permutation]\n",
    "\n",
    "print(np.shape(X_tf), np.shape(y_tf))\n",
    "print(np.shape(X_tsf), np.shape(y_tsf))\n",
    "plt.plot(y_tsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(32, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "model.fit(X_tf, y_tf, epochs=100)\n",
    "\n",
    "test_loss = model.evaluate(X_tsf, y_tsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "X_tf = np.reshape(X_tf, (X_tf.shape[0], 1, 1000))\n",
    "X_tsf = np.reshape(X_tsf, (X_tsf.shape[0], 1, 1000))\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv1D(filters=32, kernel_size=3,\n",
    "                        strides=1, padding='causal',\n",
    "                        activation='relu'),\n",
    "  tf.keras.layers.Conv1D(filters=64, kernel_size=3,\n",
    "                        strides=1, padding='causal',\n",
    "                        activation='relu'),\n",
    "  #tf.keras.layers.Dropout(0.1),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_tf, y_tf, epochs=200)\n",
    "model.summary()\n",
    "test_loss = model.evaluate(X_tsf, y_tsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
